# âš›ï¸ Atom â€” AI-Powered Search Engine

A full-stack, Perplexity-style AI search engine built with **Next.js 16** and **Express 5**. Ask any question â€” Atom searches the web in real time, scrapes and ranks sources, and streams a cited answer using the LLM of your choice.

![TypeScript](https://img.shields.io/badge/TypeScript-5.9-blue?logo=typescript&logoColor=white)
![Next.js](https://img.shields.io/badge/Next.js-16-black?logo=next.js)
![Express](https://img.shields.io/badge/Express-5-000?logo=express)
![License](https://img.shields.io/badge/License-MIT-green)

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ” **Real-Time Web Search** | Searches Google via Serper.dev API with web, news, and academic modes |
| ğŸ¤– **Multi-Provider LLM** | Choose between **OpenAI GPT-4o-mini**, **Claude 3.5 Haiku**, or **Gemini 2.5 Flash** |
| âš¡ **Native Streaming** | True token-by-token SSE streaming for all three providers |
| ğŸ“š **Source Citations** | Every claim is cited with `[1]`, `[2]`, etc. linked to ranked sources |
| ğŸ§  **Long-Term Memory** | Vector-based memory via MongoDB Atlas Search remembers past conversations |
| ğŸ“Š **Source Ranking** | Sources scored by relevance (50%), authority (30%), and freshness (20%) |
| âœ… **Answer Validation** | LLM-powered post-generation validation checks for hallucinations |
| ğŸ’¬ **Conversation History** | Persistent conversations with follow-up question generation |
| ğŸ”’ **Authentication** | Optional Clerk auth for saving conversations and user memory |
| ğŸ¨ **Modern UI** | Dark-mode interface with shadcn/ui, Framer Motion, and Tailwind CSS v4 |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Next.js 16 Client                    â”‚
â”‚  React 19 Â· Tailwind v4 Â· shadcn/ui Â· Clerk Auth       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ SSE Stream
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Express 5 API Server                   â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Search   â”‚â†’ â”‚  Scrape  â”‚â†’ â”‚  Source Ranking    â”‚    â”‚
â”‚  â”‚ (Serper)  â”‚  â”‚(Cheerio) â”‚  â”‚ Rel+Auth+Fresh     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                         â”‚               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Memory  â”‚â†’ â”‚  Query   â”‚â†’ â”‚  LLM Streaming     â”‚    â”‚
â”‚  â”‚ (Vector) â”‚  â”‚ Optimize â”‚  â”‚ OpenAI/Claude/Geminiâ”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                         â”‚
â”‚  MongoDB Â· Redis Â· BullMQ Â· LangChain                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### RAG Pipeline Flow

1. **Query Optimization** â€” LLM refines the user's query for better search results
2. **Memory Recall** â€” Vector similarity search retrieves relevant past interactions
3. **Web Search** â€” Serper.dev fetches top results (web / news / academic)
4. **Content Scraping** â€” Cheerio extracts and cleans page content (via BullMQ queue)
5. **Source Ranking** â€” Scores sources by relevance, domain authority, and freshness
6. **Context Building** â€” Top sources are deduplicated, query-relevant content extracted
7. **LLM Streaming** â€” Native streaming response with inline citations
8. **Answer Validation** â€” Post-generation check for hallucinations and unsupported claims
9. **Follow-Ups** â€” Generates contextual follow-up questions
10. **Memory Storage** â€” Stores Q&A pair as a vector embedding for future recall

---

## ğŸ› ï¸ Tech Stack

### Backend
| Technology | Purpose |
|------------|---------|
| **Express 5** | HTTP server with SSE streaming |
| **TypeScript 5.9** | Type safety across the codebase |
| **OpenAI SDK** | GPT-4o-mini completions + text-embedding-3-small |
| **Anthropic SDK** | Claude 3.5 Haiku with native streaming |
| **Google Generative AI** | Gemini 2.5 Flash with native streaming |
| **MongoDB + Mongoose** | Conversations, user data |
| **LangChain + MongoDB Atlas** | Vector search for long-term memory |
| **Redis + BullMQ** | Job queue for parallel web scraping |
| **Cheerio** | HTML parsing and content extraction |
| **Clerk** | JWT-based authentication |

### Frontend
| Technology | Purpose |
|------------|---------|
| **Next.js 16** | App Router, server components |
| **React 19** | UI rendering |
| **Tailwind CSS v4** | Styling |
| **shadcn/ui + Radix** | Component library |
| **Framer Motion** | Animations |
| **Clerk** | Auth UI components |

---

## ğŸš€ Getting Started

### Prerequisites

- **Node.js 18+**
- **MongoDB** â€” local or Atlas (required)
- **Redis** â€” optional, falls back to in-memory cache
- At least **one LLM API key** (OpenAI, Anthropic, or Gemini)

### Installation

```bash
# Clone
git clone https://github.com/your-username/atom.git
cd atom
```

**Server:**

```bash
cd server
cp .env.example .env        # â† fill in your API keys
npm install
npm run dev                  # starts on http://localhost:3001
```

**Client:**

```bash
cd client
cp .env.example .env         # â† fill in Clerk keys
npm install
npm run dev                  # starts on http://localhost:3000
```

Open [http://localhost:3000](http://localhost:3000) and start searching.

---

## âš™ï¸ Environment Variables

### Server (`server/.env`)

| Variable | Description | Required |
|----------|-------------|:--------:|
| `OPENAI_API_KEY` | OpenAI API key | âœ± |
| `ANTHROPIC_API_KEY` | Anthropic Claude API key | âœ± |
| `GEMINI_API_KEY` | Google Gemini API key | âœ± |
| `SERPER_API_KEY` | Serper.dev search API key | No (uses mock) |
| `MONGODB_URI` | MongoDB connection string | No (default: `localhost`) |
| `REDIS_URL` | Redis connection URL | No (in-memory fallback) |
| `CLERK_SECRET_KEY` | Clerk secret key | No (auth disabled) |
| `PORT` | Server port | No (default: `3001`) |
| `CORS_ORIGIN` | Allowed frontend origin | No (default: `localhost:3000`) |
| `NODE_ENV` | `development` or `production` | No (default: `development`) |

> âœ± At least **one** LLM provider key is required.

### Client (`client/.env`)

| Variable | Description | Required |
|----------|-------------|:--------:|
| `NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY` | Clerk publishable key | Yes |
| `CLERK_SECRET_KEY` | Clerk secret key | Yes |
| `NEXT_PUBLIC_CLERK_SIGN_IN_URL` | Sign-in route | No (default: `/sign-in`) |
| `NEXT_PUBLIC_CLERK_SIGN_UP_URL` | Sign-up route | No (default: `/sign-up`) |

> âš ï¸ **Never commit `.env` files.** Both are covered by `.gitignore`. Use the `.env.example` templates.

---

## ğŸ“ Project Structure

```
atom/
â”œâ”€â”€ client/                      # Next.js 16 frontend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ chat/               # Main chat page
â”‚   â”‚   â”œâ”€â”€ discover/           # News discovery page
â”‚   â”‚   â”œâ”€â”€ landing/            # Landing page
â”‚   â”‚   â”œâ”€â”€ sign-in/            # Clerk sign-in
â”‚   â”‚   â”œâ”€â”€ sign-up/            # Clerk sign-up
â”‚   â”‚   â””â”€â”€ api/discover/       # News API route
â”‚   â”œâ”€â”€ components/             # React components
â”‚   â”‚   â”œâ”€â”€ chat-interface.tsx   # Core chat UI with streaming
â”‚   â”‚   â”œâ”€â”€ sidebar.tsx          # Conversation sidebar
â”‚   â”‚   â”œâ”€â”€ source-carousel.tsx  # Source cards carousel
â”‚   â”‚   â””â”€â”€ ui/                  # shadcn/ui primitives
â”‚   â””â”€â”€ lib/                    # Utilities & API helpers
â”‚
â””â”€â”€ server/                      # Express 5 backend
    â””â”€â”€ src/
        â”œâ”€â”€ config/              # DB, Redis, queue, env config
        â”œâ”€â”€ controllers/         # HTTP request handlers
        â”œâ”€â”€ middleware/           # Auth, rate-limit, request-id
        â”œâ”€â”€ models/              # Mongoose schemas
        â”œâ”€â”€ queues/              # BullMQ job definitions
        â”œâ”€â”€ routes/              # Express route definitions
        â”œâ”€â”€ services/
        â”‚   â”œâ”€â”€ rag.service.ts           # Core RAG pipeline orchestrator
        â”‚   â”œâ”€â”€ llm.service.ts           # Multi-provider LLM abstraction
        â”‚   â”œâ”€â”€ search.service.ts        # Web search (Serper.dev)
        â”‚   â”œâ”€â”€ scrape.service.ts        # Content scraping (Cheerio)
        â”‚   â”œâ”€â”€ source-ranking.service.ts # Relevance/authority/freshness scoring
        â”‚   â”œâ”€â”€ query-optimization.service.ts # LLM-based query refinement
        â”‚   â”œâ”€â”€ answer-validation.service.ts  # Hallucination detection
        â”‚   â”œâ”€â”€ vector-store.service.ts  # Memory via vector search
        â”‚   â”œâ”€â”€ cache.service.ts         # Redis + in-memory cache
        â”‚   â””â”€â”€ conversation.service.ts  # Conversation CRUD
        â”œâ”€â”€ types/               # TypeScript type definitions
        â”œâ”€â”€ utils/               # Logger, retry, error classes
        â””â”€â”€ workers/             # BullMQ worker processes
```

---

## ğŸ“¡ API Reference

### `POST /api/chat`

Runs the full RAG pipeline and streams the response via SSE.

**Request Body:**
```json
{
  "query": "What is quantum computing?",
  "searchType": "web",
  "answerStyle": "detailed",
  "modelProvider": "openai",
  "conversationId": "optional-id-for-follow-ups"
}
```

| Field | Type | Options |
|-------|------|---------|
| `query` | `string` | Required, max 500 chars |
| `searchType` | `string` | `web` Â· `news` Â· `academic` |
| `answerStyle` | `string` | `concise` Â· `detailed` Â· `bullet-points` |
| `modelProvider` | `string` | `openai` Â· `claude` Â· `gemini` |
| `conversationId` | `string` | For continuing a conversation |

**SSE Response Events:**

| Event Type | Payload | Description |
|------------|---------|-------------|
| `status` | `string` | Pipeline progress updates |
| `sources` | `Source[]` | Ranked source list with metadata |
| `token` | `string` | Streamed answer tokens |
| `validation` | `object` | Answer quality validation result |
| `followUps` | `string[]` | Suggested follow-up questions |
| `conversationId` | `string` | ID for follow-up requests |
| `error` | `string` | Error message (sanitized) |

### `GET /api/health`

Basic health check. Returns `{ status: "ok" }`.

### `GET /api/health/detailed`

Detailed dependency status. **Requires authentication.**

### `GET /api/conversations`

List user's conversations. **Requires authentication.**

### `GET /api/conversations/:id`

Get a specific conversation. **Requires authentication.**

### `DELETE /api/conversations/:id`

Delete a conversation. **Requires authentication.**

---

## ğŸ”’ Security

- All API keys loaded from environment variables, never hardcoded
- `.env` files excluded from version control via `.gitignore`
- Internal error messages sanitized before reaching clients
- Detailed health endpoint protected behind authentication
- Rate limiting on all API routes (`express-rate-limit`)
- Request ID tracing for debugging
- CORS restricted to configured origin
- Clerk JWT verification for authenticated endpoints

---

## ğŸ“œ License

MIT
